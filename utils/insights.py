# utils/insights.py - ì¸ì‚¬ì´íŠ¸ ìƒì„± ê¸°ëŠ¥ ê°•í™”
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from config import INSIGHT_THRESHOLDS, PRODUCT_CATEGORIES, BUSINESS_KPIS, USER_SEGMENTS

def generate_data_quality_insights(df):
    """ë°ì´í„° í’ˆì§ˆì— ê´€í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    insights = []
    
    # ê²°ì¸¡ì¹˜ ë¶„ì„
    missing_percentage = df.isnull().mean() * 100
    high_missing = missing_percentage[missing_percentage > INSIGHT_THRESHOLDS['high_missing']].index.tolist()
    
    if high_missing:
        insights.append(f"âš ï¸ ë‹¤ìŒ ë³€ìˆ˜ë“¤ì€ ê²°ì¸¡ì¹˜ ë¹„ìœ¨ì´ {INSIGHT_THRESHOLDS['high_missing']}% ì´ìƒì…ë‹ˆë‹¤: {', '.join(high_missing)}")
    
    # ì¤‘ë³µ ë°ì´í„° ë¶„ì„
    duplicate_count = df.duplicated().sum()
    if duplicate_count > 0:
        duplicate_pct = duplicate_count / len(df) * 100
        if duplicate_pct > 5:
            insights.append(f"âš ï¸ ë°ì´í„°ì— {duplicate_count}ê°œ({duplicate_pct:.1f}%)ì˜ ì¤‘ë³µ í–‰ì´ ìˆìŠµë‹ˆë‹¤. ë°ì´í„° ì •ì œê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # ë¶ˆê· í˜• ë°ì´í„° í™•ì¸
    categorical_cols = df.select_dtypes(include=['object', 'category', 'bool']).columns
    for col in categorical_cols:
        value_counts = df[col].value_counts(normalize=True)
        if len(value_counts) > 1 and value_counts.iloc[0] > 0.9:
            insights.append(f"âš ï¸ '{col}' ë³€ìˆ˜ëŠ” '{value_counts.index[0]}' ê°’ì´ {value_counts.iloc[0]*100:.1f}%ë¥¼ ì°¨ì§€í•˜ëŠ” ë§¤ìš° ë¶ˆê· í˜•í•œ ë¶„í¬ë¥¼ ë³´ì…ë‹ˆë‹¤.")
    
    # ì´ìƒì¹˜ ë¶„ì„
    numeric_cols = df.select_dtypes(include=['number']).columns
    for col in numeric_cols:
        if df[col].count() > 10:  # ìµœì†Œ 10ê°œì˜ ìœ íš¨ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            outlier_count = ((df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))).sum()
            outlier_pct = outlier_count / df[col].count() * 100
            
            if outlier_pct > INSIGHT_THRESHOLDS['high_outliers']:
                insights.append(f"âš ï¸ '{col}' ë³€ìˆ˜ì— ì´ìƒì¹˜ê°€ {outlier_pct:.1f}% ìˆìŠµë‹ˆë‹¤. ë°ì´í„° ê²€í† ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    return insights

def generate_advanced_insights(df):
    """ê³ ê¸‰ ë°ì´í„° ë¶„ì„ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    insights = []
    
    # ë‚ ì§œ ì—´ í™•ì¸
    date_column = None
    for col in df.columns:
        if pd.api.types.is_datetime64_dtype(df[col]):
            date_column = col
            break
    
    # êµ°ì§‘í™” ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ (ê³ ê° ì„¸ê·¸ë¨¼íŠ¸)
    if 'user_id' in df.columns and ('total_price' in df.columns or 'price' in df.columns):
        try:
            price_col = 'total_price' if 'total_price' in df.columns else 'price'
            
            # ì‚¬ìš©ìë³„ êµ¬ë§¤ í†µê³„
            user_stats = df.groupby('user_id').agg({
                price_col: ['sum', 'mean', 'count'],
                'order_id' if 'order_id' in df.columns else 'user_id': 'count'
            })
            
            user_stats.columns = ['total_spent', 'avg_order', 'purchase_count', 'order_count']
            
            # ìµœì†Œ 10ëª… ì´ìƒì˜ ì‚¬ìš©ìê°€ ìˆì„ ë•Œë§Œ ë¶„ì„
            if len(user_stats) >= 10:
                # ê²°ì¸¡ì¹˜ ì œê±°
                user_stats = user_stats.dropna()
                
                # ìŠ¤ì¼€ì¼ë§
                from sklearn.preprocessing import StandardScaler
                scaler = StandardScaler()
                scaled_data = scaler.fit_transform(user_stats)
                
                # K-means êµ°ì§‘í™” (ì‹¤ë£¨ì—£ ì ìˆ˜ë¡œ ìµœì  êµ°ì§‘ ìˆ˜ ì°¾ê¸°)
                from sklearn.metrics import silhouette_score
                
                best_score = -1
                best_clusters = 2
                
                for n_clusters in range(2, min(6, len(user_stats) // 5)):
                    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
                    labels = kmeans.fit_predict(scaled_data)
                    
                    if len(set(labels)) > 1:  # ìµœì†Œ 2ê°œ ì´ìƒì˜ êµ°ì§‘ì´ ìˆì„ ë•Œë§Œ
                        score = silhouette_score(scaled_data, labels)
                        if score > best_score:
                            best_score = score
                            best_clusters = n_clusters
                
                # ìµœì  êµ°ì§‘ìœ¼ë¡œ ë‹¤ì‹œ í•™ìŠµ
                kmeans = KMeans(n_clusters=best_clusters, random_state=42, n_init=10)
                user_stats['cluster'] = kmeans.fit_predict(scaled_data)
                
                # êµ°ì§‘ë³„ íŠ¹ì„± ë¶„ì„
                cluster_insights = []
                for cluster in range(best_clusters):
                    cluster_data = user_stats[user_stats['cluster'] == cluster]
                    cluster_size = len(cluster_data)
                    cluster_pct = cluster_size / len(user_stats) * 100
                    
                    # êµ°ì§‘ íŠ¹ì„± í™•ì¸
                    if cluster_data['total_spent'].mean() > user_stats['total_spent'].mean() * 1.5:
                        if cluster_data['purchase_count'].mean() > user_stats['purchase_count'].mean() * 1.5:
                            cluster_type = "ê³ ê°€ì¹˜ ì¶©ì„± ê³ ê°"
                        else:
                            cluster_type = "ê³ ì•¡ êµ¬ë§¤ ê³ ê°"
                    elif cluster_data['purchase_count'].mean() > user_stats['purchase_count'].mean() * 1.5:
                        if cluster_data['avg_order'].mean() < user_stats['avg_order'].mean() * 0.8:
                            cluster_type = "ì†Œì•¡ ë‹¤ë¹ˆë„ êµ¬ë§¤ ê³ ê°"
                        else:
                            cluster_type = "ì¶©ì„± ê³ ê°"
                    elif cluster_data['avg_order'].mean() < user_stats['avg_order'].mean() * 0.6:
                        cluster_type = "ê°€ê²© ë¯¼ê° ê³ ê°"
                    else:
                        cluster_type = f"êµ°ì§‘ {cluster+1}"
                    
                    insights.append(f"ğŸ§  '{cluster_type}' ì„¸ê·¸ë¨¼íŠ¸ê°€ ì „ì²´ ê³ ê°ì˜ {cluster_pct:.1f}%ë¥¼ ì°¨ì§€í•˜ë©°, í‰ê·  {cluster_data['total_spent'].mean():,.0f}ì›ì„ ì†Œë¹„í–ˆìŠµë‹ˆë‹¤.")
        
        except Exception as e:
            pass  # êµ°ì§‘í™” ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
    
    # ì‹œê³„ì—´ íŒ¨í„´ ì¸ì‚¬ì´íŠ¸
    if date_column and 'total_price' in df.columns:
        try:
            # ì¼ë³„ ë§¤ì¶œ
            df['date'] = df[date_column].dt.date
            daily_sales = df.groupby('date')['total_price'].sum().reset_index()
            
            if len(daily_sales) >= 7:  # ìµœì†Œ 7ì¼ ë°ì´í„°
                # ìš”ì¼ë³„ ë§¤ì¶œ íŒ¨í„´
                df['weekday'] = df[date_column].dt.day_name()
                weekday_sales = df.groupby('weekday')['total_price'].sum()
                
                # ìš”ì¼ ìˆœì„œ ì •ë ¬
                weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
                weekday_sales = weekday_sales.reindex(weekday_order)
                
                top_weekday = weekday_sales.idxmax()
                bottom_weekday = weekday_sales.idxmin()
                
                # í•œê¸€ ìš”ì¼ ë³€í™˜
                weekday_kr = {
                    'Monday': 'ì›”ìš”ì¼', 'Tuesday': 'í™”ìš”ì¼', 'Wednesday': 'ìˆ˜ìš”ì¼', 
                    'Thursday': 'ëª©ìš”ì¼', 'Friday': 'ê¸ˆìš”ì¼', 'Saturday': 'í† ìš”ì¼', 'Sunday': 'ì¼ìš”ì¼'
                }
                
                insights.append(f"ğŸ“… ë§¤ì¶œì€ '{weekday_kr.get(top_weekday, top_weekday)}'ì— ê°€ì¥ ë†’ê³ , '{weekday_kr.get(bottom_weekday, bottom_weekday)}'ì— ê°€ì¥ ë‚®ìŠµë‹ˆë‹¤.")
                
                # ë§¤ì¶œ ì¦ê° ì¶”ì„¸
                if len(daily_sales) >= 14:  # ìµœì†Œ 2ì£¼ ë°ì´í„°
                    recent_sales = daily_sales.tail(7)['total_price'].sum()
                    previous_sales = daily_sales.tail(14).head(7)['total_price'].sum()
                    
                    if previous_sales > 0:
                        change_pct = (recent_sales - previous_sales) / previous_sales * 100
                        
                        if change_pct > 10:
                            insights.append(f"ğŸ“ˆ ìµœê·¼ 7ì¼ ë§¤ì¶œì´ ì´ì „ 7ì¼ ëŒ€ë¹„ {change_pct:.1f}% ì¦ê°€í–ˆìŠµë‹ˆë‹¤.")
                        elif change_pct < -10:
                            insights.append(f"ğŸ“‰ ìµœê·¼ 7ì¼ ë§¤ì¶œì´ ì´ì „ 7ì¼ ëŒ€ë¹„ {abs(change_pct):.1f}% ê°ì†Œí–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            pass  # ì‹œê³„ì—´ ë¶„ì„ ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
    
    return insights

def generate_actionable_recommendations(df):
    """ì‹¤í–‰ ê°€ëŠ¥í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì¶”ì²œì‚¬í•­ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    recommendations = []
    
    # í•„ìš”í•œ ì—´ í™•ì¸
    required_columns = ['user_id', 'total_price', 'category', 'order_date']
    missing_cols = [col for col in required_columns if col not in df.columns]
    
    if missing_cols:
        return recommendations
    
    try:
        # í˜„ì¬ ì‹œì  ì„¤ì •
        if 'order_date' in df.columns and pd.api.types.is_datetime64_dtype(df['order_date']):
            now = df['order_date'].max()
            
            # ìµœê·¼ 30ì¼ ë§¤ì¶œ ë³€í™”
            last_30_days = df[df['order_date'] >= now - timedelta(days=30)]
            previous_30_days = df[(df['order_date'] < now - timedelta(days=30)) & 
                                (df['order_date'] >= now - timedelta(days=60))]
            
            if not last_30_days.empty and not previous_30_days.empty:
                current_revenue = last_30_days['total_price'].sum()
                previous_revenue = previous_30_days['total_price'].sum()
                
                if previous_revenue > 0:
                    change_pct = (current_revenue - previous_revenue) / previous_revenue * 100
                    
                    if change_pct < -10:
                        # ì¹´í…Œê³ ë¦¬ë³„ ë³€í™” ë¶„ì„
                        current_by_category = last_30_days.groupby('category')['total_price'].sum()
                        previous_by_category = previous_30_days.groupby('category')['total_price'].sum()
                        
                        # ê³µí†µ ì¹´í…Œê³ ë¦¬
                        common_categories = set(current_by_category.index) & set(previous_by_category.index)
                        
                        category_changes = {}
                        for category in common_categories:
                            if previous_by_category[category] > 0:
                                cat_change = (current_by_category[category] - previous_by_category[category]) / previous_by_category[category] * 100
                                category_changes[category] = cat_change
                        
                        # ê°€ì¥ í° í•˜ë½ì„ ë³´ì¸ ì¹´í…Œê³ ë¦¬
                        if category_changes:
                            declining = sorted(category_changes.items(), key=lambda x: x[1])
                            worst_category = declining[0][0]
                            decline_pct = abs(declining[0][1])
                            
                            if decline_pct > 20:
                                recommendations.append(f"ğŸ’¡ '{worst_category}' ì¹´í…Œê³ ë¦¬ì˜ ë§¤ì¶œì´ {decline_pct:.1f}% í•˜ë½í–ˆìŠµë‹ˆë‹¤. ì´ ì¹´í…Œê³ ë¦¬ì— ëŒ€í•œ í”„ë¡œëª¨ì…˜ì´ë‚˜ ë§ˆì¼€íŒ… ìº í˜ì¸ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")
            
            # ì¬ë°©ë¬¸í•˜ì§€ ì•ŠëŠ” ê³ ê° ë¶„ì„
            if 'user_id' in df.columns:
                recent_90_days = df[df['order_date'] >= now - timedelta(days=90)]
                older_customers = df[(df['order_date'] < now - timedelta(days=90)) & 
                                    (df['order_date'] >= now - timedelta(days=180))]['user_id'].unique()
                
                recent_customers = set(recent_90_days['user_id'].unique())
                older_customers = set(older_customers)
                
                churned_customers = older_customers - recent_customers
                
                if older_customers:
                    churn_rate = len(churned_customers) / len(older_customers) * 100
                    
                    if churn_rate > 70:
                        recommendations.append(f"ğŸ’¡ ì§€ë‚œ 90ì¼ê°„ ì´ì „ ê³ ê°ì˜ {churn_rate:.1f}%ê°€ ì¬ë°©ë¬¸í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê³ ê° ì´íƒˆ ë°©ì§€ë¥¼ ìœ„í•œ ë¦¬í…ì…˜ í”„ë¡œê·¸ë¨ì„ ê°•í™”í•˜ì„¸ìš”.")
                    
                    # ì´íƒˆ ê³ ê°ì˜ ì„ í˜¸ ì¹´í…Œê³ ë¦¬ ë¶„ì„
                    if churned_customers:
                        churned_df = df[df['user_id'].isin(churned_customers)]
                        churned_categories = churned_df.groupby('category')['total_price'].sum().sort_values(ascending=False)
                        
                        if not churned_categories.empty:
                            top_churned_category = churned_categories.index[0]
                            recommendations.append(f"ğŸ’¡ ì´íƒˆ ê³ ê°ë“¤ì€ '{top_churned_category}' ì¹´í…Œê³ ë¦¬ì—ì„œ ê°€ì¥ ë§ì´ êµ¬ë§¤í–ˆìŠµë‹ˆë‹¤. ì´ ì¹´í…Œê³ ë¦¬ ê³ ê°ë“¤ì„ ìœ„í•œ íŠ¹ë³„ í”„ë¡œëª¨ì…˜ì„ ê³ ë ¤í•˜ì„¸ìš”.")
        
        # ì¹´í…Œê³ ë¦¬ êµì°¨ íŒë§¤ ê¸°íšŒ
        if 'category' in df.columns and 'user_id' in df.columns:
            # ì‚¬ìš©ìë³„ êµ¬ë§¤ ì¹´í…Œê³ ë¦¬
            user_categories = df.groupby('user_id')['category'].unique()
            
            # ì¹´í…Œê³ ë¦¬ ìŒ ë¶„ì„
            from collections import Counter
            category_pairs = []
            
            for categories in user_categories:
                if len(categories) >= 2:
                    for i in range(len(categories)):
                        for j in range(i+1, len(categories)):
                            category_pairs.append(tuple(sorted([categories[i], categories[j]])))
            
            if category_pairs:
                pair_counts = Counter(category_pairs)
                top_pairs = pair_counts.most_common(1)
                
                if top_pairs:
                    cat1, cat2 = top_pairs[0][0]
                    recommendations.append(f"ğŸ’¡ '{cat1}'ì™€ '{cat2}' ì¹´í…Œê³ ë¦¬ëŠ” í•¨ê»˜ êµ¬ë§¤ë˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ì´ ì¹´í…Œê³ ë¦¬ë“¤ì˜ êµì°¨ íŒë§¤ ê¸°íšŒë¥¼ í™œìš©í•˜ì„¸ìš”.")
        
        # ê°€ê²© ìµœì í™” ê¸°íšŒ
        if 'price' in df.columns and 'category' in df.columns:
            # ì¹´í…Œê³ ë¦¬ë³„ ê°€ê²© ë¶„ì„
            category_prices = df.groupby('category')['price'].agg(['mean', 'median', 'std'])
            
            for category, stats in category_prices.iterrows():
                if stats['std'] / stats['mean'] > 0.5:  # ë†’ì€ ê°€ê²© ë¶„ì‚°
                    recommendations.append(f"ğŸ’¡ '{category}' ì¹´í…Œê³ ë¦¬ì˜ ê°€ê²©ëŒ€ê°€ ë§¤ìš° ë‹¤ì–‘í•©ë‹ˆë‹¤. ê°€ê²© ë²”ìœ„ ìµœì í™”ë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš”.")
    
    except Exception as e:
        pass  # ì¶”ì²œì‚¬í•­ ìƒì„± ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
    
    return recommendations

def generate_basic_insights(df):
    """ê¸°ë³¸ì ì¸ ë°ì´í„° ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    insights = []
    
    # 1. ê²°ì¸¡ì¹˜ ë¶„ì„
    missing_percentage = df.isnull().mean() * 100
    high_missing = missing_percentage[missing_percentage > INSIGHT_THRESHOLDS['high_missing']].index.tolist()
    
    if high_missing:
        insights.append(f"ğŸ’¡ ë‹¤ìŒ ë³€ìˆ˜ë“¤ì€ ê²°ì¸¡ì¹˜ ë¹„ìœ¨ì´ {INSIGHT_THRESHOLDS['high_missing']}% ì´ìƒì…ë‹ˆë‹¤: {', '.join(high_missing)}")
    
    # 2. ìƒê´€ê´€ê³„ ë¶„ì„
    numeric_df = df.select_dtypes(include=['number'])
    if not numeric_df.empty and len(numeric_df.columns) > 1:
        corr = numeric_df.corr().abs()
        # ì¤‘ë³µ ì œê±° ë° ìê¸° ìì‹ ê³¼ì˜ ìƒê´€ê´€ê³„ ì œê±°
        corr_pairs = corr.unstack().sort_values(ascending=False).drop_duplicates()
        high_corr_pairs = corr_pairs[(corr_pairs > INSIGHT_THRESHOLDS['high_correlation']) & (corr_pairs < 1.0)]
        
        if not high_corr_pairs.empty:
            top_5_pairs = high_corr_pairs.head(5)
            for idx, corr_value in top_5_pairs.items():
                var1, var2 = idx
                insights.append(f"ğŸ’¡ {var1}ì™€ {var2} ê°„ì— ë†’ì€ ìƒê´€ê´€ê³„ê°€ ìˆìŠµë‹ˆë‹¤ (ìƒê´€ê³„ìˆ˜: {corr_value:.2f})")
    
    # 3. ë¶„í¬ ë¶„ì„ (ì™œë„)
    for col in numeric_df.columns:
        if abs(numeric_df[col].skew()) > INSIGHT_THRESHOLDS['high_skew']:
            if numeric_df[col].skew() > 0:
                insights.append(f"ğŸ’¡ {col}ì€ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì¹˜ìš°ì¹œ ë¶„í¬ë¥¼ ë³´ì…ë‹ˆë‹¤ (ì™œë„: {numeric_df[col].skew():.2f}). ë¡œê·¸ ë³€í™˜ì„ ê³ ë ¤í•´ ë³´ì„¸ìš”.")
            else:
                insights.append(f"ğŸ’¡ {col}ì€ ì™¼ìª½ìœ¼ë¡œ ì¹˜ìš°ì¹œ ë¶„í¬ë¥¼ ë³´ì…ë‹ˆë‹¤ (ì™œë„: {numeric_df[col].skew():.2f}).")
    
    return insights

def generate_today_house_insights(df):
    """ì˜¤ëŠ˜ì˜ì§‘ ë°ì´í„°ì— íŠ¹í™”ëœ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    insights = generate_basic_insights(df)
    
    # í•„ìˆ˜ ì—´ì´ ìˆëŠ”ì§€ í™•ì¸
    required_columns = ['order_date', 'total_price', 'category', 'user_id', 'product_id']
    missing_cols = [col for col in required_columns if col not in df.columns]
    
    if missing_cols:
        insights.append(f"âš ï¸ ì¼ë¶€ í•„ìˆ˜ ì—´ì´ ëˆ„ë½ë˜ì–´ ì¸ì‚¬ì´íŠ¸ ìƒì„±ì´ ì œí•œì ì…ë‹ˆë‹¤: {', '.join(missing_cols)}")
        return insights
    
    # í˜„ì¬ ì‹œì  ì„¤ì •
    now = datetime.now()
    
    # ë‚ ì§œ í˜•ì‹ í™•ì¸ ë° ë³€í™˜
    if not pd.api.types.is_datetime64_dtype(df['order_date']):
        try:
            df['order_date'] = pd.to_datetime(df['order_date'])
        except:
            insights.append("âš ï¸ 'order_date' ì—´ì„ ë‚ ì§œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ì—†ì–´ ì‹œê°„ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return insights
    
    # 1. ë§¤ì¶œ íŠ¸ë Œë“œ ë¶„ì„
    try:
        # ì›”ë³„ ë§¤ì¶œ ì§‘ê³„
        monthly_sales = df.groupby(df['order_date'].dt.to_period('M'))['total_price'].sum()
        
        if len(monthly_sales) > 1:
            last_month = monthly_sales.index[-1]
            prev_month = monthly_sales.index[-2]
            
            change_pct = (monthly_sales[last_month] - monthly_sales[prev_month]) / monthly_sales[prev_month] * 100
            
            if change_pct > 10:
                insights.append(f"ğŸ’° ìµœê·¼ ì›” ë§¤ì¶œì´ ì „ì›” ëŒ€ë¹„ {change_pct:.1f}% ì¦ê°€í–ˆìŠµë‹ˆë‹¤. ì„±ì¥ì„¸ê°€ ê°•í•©ë‹ˆë‹¤.")
            elif change_pct > 5:
                insights.append(f"ğŸ’° ìµœê·¼ ì›” ë§¤ì¶œì´ ì „ì›” ëŒ€ë¹„ {change_pct:.1f}% ì¦ê°€í–ˆìŠµë‹ˆë‹¤. ì•ˆì •ì ì¸ ì„±ì¥ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.")
            elif change_pct < -10:
                insights.append(f"âš ï¸ ìµœê·¼ ì›” ë§¤ì¶œì´ ì „ì›” ëŒ€ë¹„ {abs(change_pct):.1f}% ê°ì†Œí–ˆìŠµë‹ˆë‹¤. ì›ì¸ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            elif change_pct < -5:
                insights.append(f"âš ï¸ ìµœê·¼ ì›” ë§¤ì¶œì´ ì „ì›” ëŒ€ë¹„ {abs(change_pct):.1f}% ê°ì†Œí–ˆìŠµë‹ˆë‹¤. ì£¼ì˜ ê¹Šì€ ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    except Exception as e:
        insights.append(f"âš ï¸ ë§¤ì¶œ íŠ¸ë Œë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    # 2. ì¹´í…Œê³ ë¦¬ ì¸ì‚¬ì´íŠ¸
    try:
        category_sales = df.groupby('category')['total_price'].sum().sort_values(ascending=False)
        top_category = category_sales.index[0]
        top_category_pct = category_sales[top_category] / category_sales.sum() * 100
        
        # ìµœê·¼ 3ê°œì›” ë°ì´í„°
        three_months_ago = now - timedelta(days=90)
        recent_df = df[df['order_date'] >= three_months_ago]
        
        if not recent_df.empty:
            recent_category_sales = recent_df.groupby('category')['total_price'].sum().sort_values(ascending=False)
            recent_top_category = recent_category_sales.index[0]
            
            if recent_top_category != top_category:
                insights.append(f"ğŸ“Š ì „ì²´ ê¸°ê°„ì—ëŠ” '{top_category}'ì´(ê°€) ìµœê³  ë§¤ì¶œ ì¹´í…Œê³ ë¦¬ì˜€ìœ¼ë‚˜, ìµœê·¼ 3ê°œì›”ê°„ì€ '{recent_top_category}'ì´(ê°€) ê°€ì¥ ë†’ì€ ë§¤ì¶œì„ ê¸°ë¡í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
            else:
                insights.append(f"ğŸ“Š '{top_category}' ì¹´í…Œê³ ë¦¬ê°€ ì „ì²´ ë§¤ì¶œì˜ {top_category_pct:.1f}%ë¥¼ ì°¨ì§€í•˜ë©° ì§€ì†ì ìœ¼ë¡œ ì¸ê¸°ë¥¼ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        
        # ì„±ì¥ë¥ ì´ ê°€ì¥ ë†’ì€ ì¹´í…Œê³ ë¦¬ ì°¾ê¸°
        if len(monthly_sales) > 3:  # ìµœì†Œ 3ê°œì›” ë°ì´í„° í•„ìš”
            # ìµœê·¼ 3ê°œì›”ê³¼ ì´ì „ 3ê°œì›” ë¹„êµ
            recent_3_months = df[df['order_date'] >= now - timedelta(days=90)]
            previous_3_months = df[(df['order_date'] < now - timedelta(days=90)) & 
                                    (df['order_date'] >= now - timedelta(days=180))]
            
            if not recent_3_months.empty and not previous_3_months.empty:
                recent_by_category = recent_3_months.groupby('category')['total_price'].sum()
                previous_by_category = previous_3_months.groupby('category')['total_price'].sum()
                
                # ë‘ ê¸°ê°„ ëª¨ë‘ ë°ì´í„°ê°€ ìˆëŠ” ì¹´í…Œê³ ë¦¬ë§Œ ë¹„êµ
                common_categories = set(recent_by_category.index) & set(previous_by_category.index)
                
                growth_rates = {}
                for category in common_categories:
                    if previous_by_category[category] > 0:
                        growth_rate = (recent_by_category[category] - previous_by_category[category]) / previous_by_category[category] * 100
                        growth_rates[category] = growth_rate
                
                if growth_rates:
                    fastest_growing = max(growth_rates.items(), key=lambda x: x[1])
                    if fastest_growing[1] > 30:  # 30% ì´ìƒ ì„±ì¥í•œ ê²½ìš°ë§Œ
                        insights.append(f"ğŸ“ˆ '{fastest_growing[0]}' ì¹´í…Œê³ ë¦¬ê°€ ì „ë¶„ê¸° ëŒ€ë¹„ {fastest_growing[1]:.1f}% ì„±ì¥í•˜ë©° ê°€ì¥ ë¹ ë¥¸ ì„±ì¥ì„¸ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.")
                    
                    declining = [(cat, rate) for cat, rate in growth_rates.items() if rate < -20]
                    if declining:
                        declining.sort(key=lambda x: x[1])
                        insights.append(f"ğŸ“‰ '{declining[0][0]}' ì¹´í…Œê³ ë¦¬ê°€ ì „ë¶„ê¸° ëŒ€ë¹„ {abs(declining[0][1]):.1f}% ê°ì†Œí•˜ë©° ê°€ì¥ í° í•˜ë½ì„¸ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        insights.append(f"âš ï¸ ì¹´í…Œê³ ë¦¬ ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    # 3. ê³ ê° í–‰ë™ ì¸ì‚¬ì´íŠ¸
    try:
        # ì¬êµ¬ë§¤ìœ¨ ë¶„ì„
        user_order_counts = df['user_id'].value_counts()
        repeat_buyers = user_order_counts[user_order_counts > 1].count()
        repeat_rate = repeat_buyers / user_order_counts.count() * 100
        
        insights.append(f"ğŸ‘¥ ì „ì²´ ê³ ê° ì¤‘ {repeat_rate:.1f}%ê°€ ì¬êµ¬ë§¤ë¥¼ í•œ ì¶©ì„± ê³ ê°ì…ë‹ˆë‹¤.")
        
        # ìµœê·¼ 30ì¼ ì‹ ê·œ ê³ ê° ë¹„ìœ¨
        recent_month = df[df['order_date'] >= now - timedelta(days=30)]
        if not recent_month.empty:
            recent_users = recent_month['user_id'].unique()
            existing_users = df[df['order_date'] < now - timedelta(days=30)]['user_id'].unique()
            new_users = set(recent_users) - set(existing_users)
            new_user_rate = len(new_users) / len(recent_users) * 100
            
            if new_user_rate > 30:
                insights.append(f"ğŸ†• ìµœê·¼ 30ì¼ êµ¬ë§¤ì ì¤‘ {new_user_rate:.1f}%ê°€ ì‹ ê·œ ê³ ê°ìœ¼ë¡œ, ì‹ ê·œ ìœ ì…ì´ í™œë°œí•©ë‹ˆë‹¤.")
            elif new_user_rate < 10:
                insights.append(f"âš ï¸ ìµœê·¼ 30ì¼ êµ¬ë§¤ì ì¤‘ ì‹ ê·œ ê³ ê° ë¹„ìœ¨ì´ {new_user_rate:.1f}%ë¡œ ë‚®ìŠµë‹ˆë‹¤. ì‹ ê·œ ê³ ê° ìœ ì¹˜ ì „ëµì´ í•„ìš”í•©ë‹ˆë‹¤.")
    except Exception as e:
        insights.append(f"âš ï¸ ê³ ê° í–‰ë™ ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    # 4. ê°€ê²©ëŒ€ë³„ ì¸ì‚¬ì´íŠ¸
    try:
        # ê°€ê²©ëŒ€ ë¶„ë¥˜
        price_bins = [0, 10000, 30000, 50000, 100000, float('inf')]
        price_labels = ['1ë§Œì› ë¯¸ë§Œ', '1-3ë§Œì›', '3-5ë§Œì›', '5-10ë§Œì›', '10ë§Œì› ì´ìƒ']
        
        df['price_range'] = pd.cut(df['total_price'], bins=price_bins, labels=price_labels)
        price_range_counts = df['price_range'].value_counts(normalize=True) * 100
        
        if '10ë§Œì› ì´ìƒ' in price_range_counts and price_range_counts['10ë§Œì› ì´ìƒ'] > 25:
            insights.append(f"ğŸ’ 10ë§Œì› ì´ìƒ ê³ ê°€ ìƒí’ˆì´ ì „ì²´ ì£¼ë¬¸ì˜ {price_range_counts['10ë§Œì› ì´ìƒ']:.1f}%ë¥¼ ì°¨ì§€í•˜ì—¬ ê³ ê°€ ì œí’ˆ ë¹„ì¤‘ì´ ë†’ìŠµë‹ˆë‹¤.")
        elif '1ë§Œì› ë¯¸ë§Œ' in price_range_counts and price_range_counts['1ë§Œì› ë¯¸ë§Œ'] > 40:
            insights.append(f"ğŸ·ï¸ 1ë§Œì› ë¯¸ë§Œ ì €ê°€ ìƒí’ˆì´ ì „ì²´ ì£¼ë¬¸ì˜ {price_range_counts['1ë§Œì› ë¯¸ë§Œ']:.1f}%ë¥¼ ì°¨ì§€í•©ë‹ˆë‹¤. ê°ë‹¨ê°€ ìƒìŠ¹ ì „ëµì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")
        
        # ê°ë‹¨ê°€ íŠ¸ë Œë“œ
        if len(monthly_sales) > 1:
            monthly_orders = df.groupby(df['order_date'].dt.to_period('M'))['order_id'].count()
            monthly_aov = monthly_sales / monthly_orders
            
            last_month_aov = monthly_aov.iloc[-1]
            prev_month_aov = monthly_aov.iloc[-2]
            
            aov_change = (last_month_aov - prev_month_aov) / prev_month_aov * 100
            
            if aov_change > 10:
                insights.append(f"ğŸ’° ìµœê·¼ ì›” ê°ë‹¨ê°€ê°€ {last_month_aov:,.0f}ì›ìœ¼ë¡œ ì „ì›” ëŒ€ë¹„ {aov_change:.1f}% ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤.")
            elif aov_change < -10:
                insights.append(f"âš ï¸ ìµœê·¼ ì›” ê°ë‹¨ê°€ê°€ {last_month_aov:,.0f}ì›ìœ¼ë¡œ ì „ì›” ëŒ€ë¹„ {abs(aov_change):.1f}% í•˜ë½í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        insights.append(f"âš ï¸ ê°€ê²©ëŒ€ ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    # 5. ê³„ì ˆì„± ë° ì‹œê°„ íŒ¨í„´ ì¸ì‚¬ì´íŠ¸
    try:
        # ìš”ì¼ë³„ ì£¼ë¬¸ íŒ¨í„´
        df['weekday'] = df['order_date'].dt.day_name()
        weekday_orders = df['weekday'].value_counts()
        top_weekday = weekday_orders.index[0]
        
        # ì‹œê°„ëŒ€ë³„ ì£¼ë¬¸ íŒ¨í„´
        df['hour'] = df['order_date'].dt.hour
        
        # ì•„ì¹¨(6-10), ì ì‹¬(11-14), ì˜¤í›„(15-18), ì €ë…(19-22), ë°¤(23-5)
        df['time_of_day'] = pd.cut(
            df['hour'], 
            bins=[-1, 5, 10, 14, 18, 22, 24], 
            labels=['ë°¤', 'ì•„ì¹¨', 'ì ì‹¬', 'ì˜¤í›„', 'ì €ë…', 'ë°¤']
        )
        
        time_of_day_orders = df['time_of_day'].value_counts()
        peak_time = time_of_day_orders.index[0]
        
        insights.append(f"ğŸ•’ ì£¼ë¬¸ì€ '{top_weekday}'ìš”ì¼ê³¼ '{peak_time}' ì‹œê°„ëŒ€ì— ê°€ì¥ ë§ì´ ë°œìƒí•©ë‹ˆë‹¤. ì´ ì‹œê°„ëŒ€ë¥¼ íƒ€ê²ŸíŒ…í•œ ë§ˆì¼€íŒ…ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")
        
        # ê³„ì ˆì„± ë¶„ì„
        df['month'] = df['order_date'].dt.month
        month_orders = df.groupby('month')['order_id'].count()
        
        # ê³„ì ˆë³„ ì£¼ë¬¸ëŸ‰
        seasons = {
            'ë´„': [3, 4, 5],
            'ì—¬ë¦„': [6, 7, 8],
            'ê°€ì„': [9, 10, 11],
            'ê²¨ìš¸': [12, 1, 2]
        }
        
        season_orders = {}
        for season, months in seasons.items():
            season_orders[season] = df[df['month'].isin(months)]['order_id'].count()
        
        top_season = max(season_orders.items(), key=lambda x: x[1])[0]
        bottom_season = min(season_orders.items(), key=lambda x: x[1])[0]
        
        season_ratio = season_orders[top_season] / season_orders[bottom_season]
        
        if season_ratio > 1.5:
            insights.append(f"ğŸŒˆ '{top_season}'ì´ ê°€ì¥ ì£¼ë¬¸ì´ ë§ì€ ê³„ì ˆì´ë©°, '{bottom_season}'ë³´ë‹¤ {season_ratio:.1f}ë°° ë” ë§ì€ ì£¼ë¬¸ì´ ë°œìƒí•©ë‹ˆë‹¤. ê³„ì ˆì„±ì´ ëšœë ·í•©ë‹ˆë‹¤.")
    except Exception as e:
        insights.append(f"âš ï¸ ì‹œê°„ íŒ¨í„´ ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    # 6. ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ ì¸ì‚¬ì´íŠ¸
    if 'user_segment' in df.columns:
        try:
            segment_counts = df['user_segment'].value_counts(normalize=True) * 100
            segment_sales = df.groupby('user_segment')['total_price'].sum()
            total_sales = segment_sales.sum()
            
            # ì„¸ê·¸ë¨¼íŠ¸ë³„ ë§¤ì¶œ ê¸°ì—¬ë„
            segment_contribution = (segment_sales / total_sales * 100).sort_values(ascending=False)
            
            top_segment = segment_contribution.index[0]
            top_segment_contribution = segment_contribution[top_segment]
            
            segment_name = USER_SEGMENTS[top_segment]['name'] if top_segment in USER_SEGMENTS else top_segment
            
            insights.append(f"ğŸ‘‘ '{segment_name}' ì„¸ê·¸ë¨¼íŠ¸ê°€ ì „ì²´ ë§¤ì¶œì˜ {top_segment_contribution:.1f}%ë¥¼ ì°¨ì§€í•˜ë©° ê°€ì¥ ê°€ì¹˜ ìˆëŠ” ê³ ê°ì¸µì…ë‹ˆë‹¤.")
            
            # ë¹„í™œì„± ê³ ê° ë¹„ìœ¨
            if 'at_risk_customers' in segment_counts:
                at_risk_pct = segment_counts['at_risk_customers']
                if at_risk_pct > 30:
                    insights.append(f"âš ï¸ ì „ì²´ ê³ ê° ì¤‘ {at_risk_pct:.1f}%ê°€ 'ì´íƒˆ ìœ„í—˜' ìƒíƒœë¡œ, ì¬í™œì„±í™” ìº í˜ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        except Exception as e:
            insights.append(f"âš ï¸ ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    # 7. ë² ìŠ¤íŠ¸ ì…€ëŸ¬ ì œí’ˆ ì¸ì‚¬ì´íŠ¸
    try:
        product_sales = df.groupby('product_id')['total_price'].sum().sort_values(ascending=False)
        top_products = product_sales.head(5).index.tolist()
        
        if 'product_name' in df.columns:
            top_product_names = df[df['product_id'].isin(top_products)]['product_name'].unique()
            if len(top_product_names) > 0:
                insights.append(f"ğŸ† ë² ìŠ¤íŠ¸ì…€ëŸ¬ ìƒí’ˆì€ '{top_product_names[0]}' ë“±ìœ¼ë¡œ, ì´ëŸ¬í•œ ì¸ê¸° ìƒí’ˆì„ í™ë³´ ì „ëµì— í™œìš©í•´ë³´ì„¸ìš”.")
    except Exception as e:
        insights.append(f"âš ï¸ ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    return insights

def generate_time_series_insights(df, date_column):
    """ì‹œê³„ì—´ ë°ì´í„°ì— ëŒ€í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    insights = []
    
    if date_column in df.columns:
        # ë‚ ì§œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        df['date'] = pd.to_datetime(df[date_column])
        
        # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ì— ëŒ€í•´ ì‹œê³„ì—´ ë¶„ì„
        numeric_cols = df.select_dtypes(include=['number']).columns
        
        for col in numeric_cols:
            # ì‹œê°„ì— ë”°ë¥¸ ì¶”ì„¸ (ê°„ë‹¨í•œ ì„ í˜• íšŒê·€)
            if len(df) > 5:  # ìµœì†Œ ë°ì´í„° í¬ì¸íŠ¸ í•„ìš”
                df['time_idx'] = range(len(df))
                corr = df[['time_idx', col]].corr().iloc[0, 1]
                
                if abs(corr) > 0.7:
                    trend_direction = "ì¦ê°€" if corr > 0 else "ê°ì†Œ"
                    insights.append(f"ğŸ’¡ {col}ì€ ì‹œê°„ì— ë”°ë¼ {trend_direction}í•˜ëŠ” ê°•í•œ ì¶”ì„¸ë¥¼ ë³´ì…ë‹ˆë‹¤ (ìƒê´€ê³„ìˆ˜: {corr:.2f}).")
    
    return insights

def generate_kpi_insights(df):
    """ë¹„ì¦ˆë‹ˆìŠ¤ KPI ê´€ë ¨ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    insights = []
    
    # í•„ìˆ˜ ì—´ì´ ìˆëŠ”ì§€ í™•ì¸
    required_columns = ['order_date', 'total_price', 'user_id', 'product_id']
    missing_cols = [col for col in required_columns if col not in df.columns]
    
    if missing_cols:
        insights.append(f"âš ï¸ ì¼ë¶€ í•„ìˆ˜ ì—´ì´ ëˆ„ë½ë˜ì–´ KPI ì¸ì‚¬ì´íŠ¸ ìƒì„±ì´ ì œí•œì ì…ë‹ˆë‹¤: {', '.join(missing_cols)}")
        return insights
    
    try:
        # í˜„ì¬ ì‹œì  ì„¤ì • (ë°ì´í„°ì˜ ë§ˆì§€ë§‰ ë‚ ì§œë¥¼ í˜„ì¬ë¡œ ê°„ì£¼)
        df['order_date'] = pd.to_datetime(df['order_date'])
        current_date = df['order_date'].max()
        
        # ìµœê·¼ 30ì¼ ë°ì´í„°
        last_30_days = df[df['order_date'] >= current_date - timedelta(days=30)]
        
        # ì´ì „ 30ì¼ ë°ì´í„°
        previous_30_days = df[(df['order_date'] < current_date - timedelta(days=30)) & 
                              (df['order_date'] >= current_date - timedelta(days=60))]
        
        # 1. ë§¤ì¶œì•¡ KPI
        current_revenue = last_30_days['total_price'].sum()
        previous_revenue = previous_30_days['total_price'].sum()
        
        if previous_revenue > 0:
            revenue_growth = (current_revenue - previous_revenue) / previous_revenue * 100
            target_growth = BUSINESS_KPIS['revenue']['target_increase'] * 100
            
            if revenue_growth >= target_growth:
                insights.append(f"ğŸ¯ ìµœê·¼ 30ì¼ ë§¤ì¶œì•¡ì´ {current_revenue:,.0f}ì›ìœ¼ë¡œ ëª©í‘œ ì„±ì¥ë¥ ({target_growth:.1f}%)ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. (ì‹¤ì œ ì„±ì¥ë¥ : {revenue_growth:.1f}%)")
            else:
                insights.append(f"ğŸ“Š ìµœê·¼ 30ì¼ ë§¤ì¶œì•¡ì€ {current_revenue:,.0f}ì›ìœ¼ë¡œ ëª©í‘œ ì„±ì¥ë¥ ({target_growth:.1f}%)ì— ë¯¸ë‹¬í•©ë‹ˆë‹¤. (ì‹¤ì œ ì„±ì¥ë¥ : {revenue_growth:.1f}%)")
        
        # 2. ì „í™˜ìœ¨ KPI (ê°€ì •: ë°©ë¬¸ ë°ì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ ì£¼ë¬¸ ê±´ìˆ˜ / ê³ ìœ  ì‚¬ìš©ì ìˆ˜ë¡œ ëŒ€ì²´)
        current_orders = last_30_days['order_id'].nunique()
        current_users = last_30_days['user_id'].nunique()
        
        if current_users > 0:
            conversion_rate = current_orders / current_users * 100
            target_conversion = BUSINESS_KPIS['conversion_rate']['target_value']
            
            if conversion_rate >= target_conversion:
                insights.append(f"ğŸ¯ ìµœê·¼ 30ì¼ ì „í™˜ìœ¨ì´ {conversion_rate:.2f}%ë¡œ ëª©í‘œ({target_conversion:.2f}%)ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.")
            else:
                gap = target_conversion - conversion_rate
                insights.append(f"ğŸ“Š ìµœê·¼ 30ì¼ ì „í™˜ìœ¨ì€ {conversion_rate:.2f}%ë¡œ ëª©í‘œ({target_conversion:.2f}%)ê¹Œì§€ {gap:.2f}%p ë‚¨ì•˜ìŠµë‹ˆë‹¤.")
        
        # 3. ê°ë‹¨ê°€ KPI
        current_aov = current_revenue / current_orders if current_orders > 0 else 0
        target_aov = BUSINESS_KPIS['average_order_value']['target_value']
        
        if current_aov > 0:
            if current_aov >= target_aov:
                insights.append(f"ğŸ¯ ìµœê·¼ 30ì¼ ê°ë‹¨ê°€ê°€ {current_aov:,.0f}ì›ìœ¼ë¡œ ëª©í‘œ({target_aov:,.0f}ì›)ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.")
            else:
                gap_percent = (target_aov - current_aov) / target_aov * 100
                insights.append(f"ğŸ“Š ìµœê·¼ 30ì¼ ê°ë‹¨ê°€ëŠ” {current_aov:,.0f}ì›ìœ¼ë¡œ ëª©í‘œ({target_aov:,.0f}ì›)ë³´ë‹¤ {gap_percent:.1f}% ë‚®ìŠµë‹ˆë‹¤.")
        
        # 4. ì¬êµ¬ë§¤ìœ¨ KPI
        # ìµœê·¼ 30ì¼ êµ¬ë§¤ì ì¤‘ ì´ì „ 30ì¼ì—ë„ êµ¬ë§¤í•œ ë¹„ìœ¨
        current_buyers = set(last_30_days['user_id'].unique())
        previous_buyers = set(previous_30_days['user_id'].unique())
        
        returning_buyers = current_buyers.intersection(previous_buyers)
        
        if current_buyers:
            retention_rate = len(returning_buyers) / len(current_buyers) * 100
            target_retention = BUSINESS_KPIS['retention_rate']['target_value']
            
            if retention_rate >= target_retention:
                insights.append(f"ğŸ¯ ìµœê·¼ 30ì¼ ì¬êµ¬ë§¤ìœ¨ì´ {retention_rate:.1f}%ë¡œ ëª©í‘œ({target_retention:.1f}%)ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.")
            else:
                insights.append(f"ğŸ“Š ìµœê·¼ 30ì¼ ì¬êµ¬ë§¤ìœ¨ì€ {retention_rate:.1f}%ë¡œ ëª©í‘œ({target_retention:.1f}%)ì— ë¯¸ë‹¬í•©ë‹ˆë‹¤.")
    
    except Exception as e:
        insights.append(f"âš ï¸ KPI ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    return insights